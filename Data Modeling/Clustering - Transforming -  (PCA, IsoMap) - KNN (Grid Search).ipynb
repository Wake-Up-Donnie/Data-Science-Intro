{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module5- Lab7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "matplotlib.style.use('ggplot') # Look Pretty\n",
    "\n",
    "\n",
    "# Leave this alone until indicated:\n",
    "Test_PCA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Convenience Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is for your visualization convenience only. You aren't expected to know how to put this together yourself, although you should be able to follow the code by now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotDecisionBoundary(model, X, y):\n",
    "    print(\"Plotting...\")\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    padding = 0.1\n",
    "    resolution = 0.1\n",
    "\n",
    "    #(2 for benign, 4 for malignant)\n",
    "    colors = {2:'royalblue', 4:'lightsalmon'} \n",
    "\n",
    "\n",
    "    # Calculate the boundaris\n",
    "    x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "    y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= x_range * padding\n",
    "    y_min -= y_range * padding\n",
    "    x_max += x_range * padding\n",
    "    y_max += y_range * padding\n",
    "\n",
    "    # Create a 2D Grid Matrix. The values stored in the matrix\n",
    "    # are the predictions of the class at at said location\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                         np.arange(y_min, y_max, resolution))\n",
    "\n",
    "    # What class does the classifier say?\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour map\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.seismic)\n",
    "    plt.axis('tight')\n",
    "\n",
    "    # Plot your testing points as well...\n",
    "    for label in np.unique(y):\n",
    "        indices = np.where(y == label)\n",
    "        plt.scatter(X[indices, 0], X[indices, 1], c=colors[label], alpha=0.8)\n",
    "\n",
    "    p = model.get_params()\n",
    "    plt.title('K = ' + str(p['n_neighbors']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load in the dataset, identify nans, and set proper headers. Be sure to verify the rows line up by looking at the file in a text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample  thickness  size  shape  adhesion  epithelial nuclei  chromatin  \\\n",
      "0  1000025          5     1      1         1           2      1          3   \n",
      "1  1002945          5     4      4         5           7     10          3   \n",
      "2  1015425          3     1      1         1           2      2          3   \n",
      "3  1016277          6     8      8         1           3      4          3   \n",
      "4  1017023          4     1      1         3           2      1          3   \n",
      "\n",
      "   nucleoli  mitoses  status  \n",
      "0         1        1       2  \n",
      "1         2        1       2  \n",
      "2         1        1       2  \n",
      "3         7        1       2  \n",
      "4         1        1       2  \n",
      "sample         int64\n",
      "thickness      int64\n",
      "size           int64\n",
      "shape          int64\n",
      "adhesion       int64\n",
      "epithelial     int64\n",
      "nuclei        object\n",
      "chromatin      int64\n",
      "nucleoli       int64\n",
      "mitoses        int64\n",
      "status         int64\n",
      "dtype: object\n",
      "sample          int64\n",
      "thickness       int64\n",
      "size            int64\n",
      "shape           int64\n",
      "adhesion        int64\n",
      "epithelial      int64\n",
      "nuclei        float64\n",
      "chromatin       int64\n",
      "nucleoli        int64\n",
      "mitoses         int64\n",
      "status          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('Datasets/breast-cancer-wisconsin.data', sep = \",\", names = ['sample', 'thickness', 'size', 'shape', 'adhesion', 'epithelial', 'nuclei', 'chromatin', 'nucleoli', 'mitoses', 'status'])\n",
    "print (X.head())\n",
    "print (X.dtypes)\n",
    "X.nuclei = pd.to_numeric(X.nuclei, errors = 'coerce')\n",
    "print (X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy out the status column into a slice, then drop it from the main dataframe. Always verify you properly executed the drop by double checking (printing out the resulting operating)! Many people forget to set the right axis here.\n",
    "\n",
    "If you goofed up on loading the dataset and notice you have a `sample` column, this would be a good place to drop that too if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     thickness  size  shape  adhesion  epithelial  nuclei  chromatin  \\\n",
      "0            5     1      1         1           2     1.0          3   \n",
      "1            5     4      4         5           7    10.0          3   \n",
      "2            3     1      1         1           2     2.0          3   \n",
      "3            6     8      8         1           3     4.0          3   \n",
      "4            4     1      1         3           2     1.0          3   \n",
      "5            8    10     10         8           7    10.0          9   \n",
      "6            1     1      1         1           2    10.0          3   \n",
      "7            2     1      2         1           2     1.0          3   \n",
      "8            2     1      1         1           2     1.0          1   \n",
      "9            4     2      1         1           2     1.0          2   \n",
      "10           1     1      1         1           1     1.0          3   \n",
      "11           2     1      1         1           2     1.0          2   \n",
      "12           5     3      3         3           2     3.0          4   \n",
      "13           1     1      1         1           2     3.0          3   \n",
      "14           8     7      5        10           7     9.0          5   \n",
      "15           7     4      6         4           6     1.0          4   \n",
      "16           4     1      1         1           2     1.0          2   \n",
      "17           4     1      1         1           2     1.0          3   \n",
      "18          10     7      7         6           4    10.0          4   \n",
      "19           6     1      1         1           2     1.0          3   \n",
      "20           7     3      2        10           5    10.0          5   \n",
      "21          10     5      5         3           6     7.0          7   \n",
      "22           3     1      1         1           2     1.0          2   \n",
      "23           8     4      5         1           2     NaN          7   \n",
      "24           1     1      1         1           2     1.0          3   \n",
      "25           5     2      3         4           2     7.0          3   \n",
      "26           3     2      1         1           1     1.0          2   \n",
      "27           5     1      1         1           2     1.0          2   \n",
      "28           2     1      1         1           2     1.0          2   \n",
      "29           1     1      3         1           2     1.0          1   \n",
      "..         ...   ...    ...       ...         ...     ...        ...   \n",
      "669          5    10     10         8           5     5.0          7   \n",
      "670          3    10      7         8           5     8.0          7   \n",
      "671          3     2      1         2           2     1.0          3   \n",
      "672          2     1      1         1           2     1.0          3   \n",
      "673          5     3      2         1           3     1.0          1   \n",
      "674          1     1      1         1           2     1.0          2   \n",
      "675          4     1      4         1           2     1.0          1   \n",
      "676          1     1      2         1           2     1.0          2   \n",
      "677          5     1      1         1           2     1.0          1   \n",
      "678          1     1      1         1           2     1.0          1   \n",
      "679          2     1      1         1           2     1.0          1   \n",
      "680         10    10     10        10           5    10.0         10   \n",
      "681          5    10     10        10           4    10.0          5   \n",
      "682          5     1      1         1           2     1.0          3   \n",
      "683          1     1      1         1           2     1.0          1   \n",
      "684          1     1      1         1           2     1.0          1   \n",
      "685          1     1      1         1           2     1.0          1   \n",
      "686          1     1      1         1           2     1.0          1   \n",
      "687          3     1      1         1           2     1.0          2   \n",
      "688          4     1      1         1           2     1.0          1   \n",
      "689          1     1      1         1           2     1.0          1   \n",
      "690          1     1      1         3           2     1.0          1   \n",
      "691          5    10     10         5           4     5.0          4   \n",
      "692          3     1      1         1           2     1.0          1   \n",
      "693          3     1      1         1           2     1.0          2   \n",
      "694          3     1      1         1           3     2.0          1   \n",
      "695          2     1      1         1           2     1.0          1   \n",
      "696          5    10     10         3           7     3.0          8   \n",
      "697          4     8      6         4           3     4.0         10   \n",
      "698          4     8      8         5           4     5.0         10   \n",
      "\n",
      "     nucleoli  mitoses  \n",
      "0           1        1  \n",
      "1           2        1  \n",
      "2           1        1  \n",
      "3           7        1  \n",
      "4           1        1  \n",
      "5           7        1  \n",
      "6           1        1  \n",
      "7           1        1  \n",
      "8           1        5  \n",
      "9           1        1  \n",
      "10          1        1  \n",
      "11          1        1  \n",
      "12          4        1  \n",
      "13          1        1  \n",
      "14          5        4  \n",
      "15          3        1  \n",
      "16          1        1  \n",
      "17          1        1  \n",
      "18          1        2  \n",
      "19          1        1  \n",
      "20          4        4  \n",
      "21         10        1  \n",
      "22          1        1  \n",
      "23          3        1  \n",
      "24          1        1  \n",
      "25          6        1  \n",
      "26          1        1  \n",
      "27          1        1  \n",
      "28          1        1  \n",
      "29          1        1  \n",
      "..        ...      ...  \n",
      "669        10        1  \n",
      "670         4        1  \n",
      "671         1        1  \n",
      "672         1        1  \n",
      "673         1        1  \n",
      "674         1        1  \n",
      "675         1        1  \n",
      "676         1        1  \n",
      "677         1        1  \n",
      "678         1        1  \n",
      "679         1        1  \n",
      "680        10        7  \n",
      "681         6        3  \n",
      "682         2        1  \n",
      "683         1        1  \n",
      "684         1        1  \n",
      "685         1        1  \n",
      "686         1        1  \n",
      "687         3        1  \n",
      "688         1        1  \n",
      "689         1        8  \n",
      "690         1        1  \n",
      "691         4        1  \n",
      "692         1        1  \n",
      "693         1        2  \n",
      "694         1        1  \n",
      "695         1        1  \n",
      "696        10        2  \n",
      "697         6        1  \n",
      "698         4        1  \n",
      "\n",
      "[699 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "y = X['status'].copy()\n",
    "X = X.drop(['status', 'sample'], axis=1)\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the labels safely extracted from the dataset, replace any nan values with the mean feature / column value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do train_test_split. Use the same variable names as on the EdX platform in the reading material, but set the random_state=7 for reproducibility, and keep the test_size at 0.5 (50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the basic SKLearn preprocessing scalers. We know that the features consist of different units mixed in together, so it might be reasonable to assume feature scaling is necessary. Print out a description of the dataset, post transformation. Recall: when you do pre-processing, which portion of the dataset is your model trained upon? Also which portion(s) of your dataset actually get transformed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thickness</th>\n",
       "      <th>size</th>\n",
       "      <th>shape</th>\n",
       "      <th>adhesion</th>\n",
       "      <th>epithelial</th>\n",
       "      <th>nuclei</th>\n",
       "      <th>chromatin</th>\n",
       "      <th>nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.495702</td>\n",
       "      <td>3.212034</td>\n",
       "      <td>3.326648</td>\n",
       "      <td>2.888252</td>\n",
       "      <td>3.289398</td>\n",
       "      <td>3.529037</td>\n",
       "      <td>3.469914</td>\n",
       "      <td>2.896848</td>\n",
       "      <td>1.621777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.946478</td>\n",
       "      <td>3.159691</td>\n",
       "      <td>3.067611</td>\n",
       "      <td>2.887071</td>\n",
       "      <td>2.305522</td>\n",
       "      <td>3.651567</td>\n",
       "      <td>2.406250</td>\n",
       "      <td>3.075808</td>\n",
       "      <td>1.814750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        thickness        size       shape    adhesion  epithelial      nuclei  \\\n",
       "count  349.000000  349.000000  349.000000  349.000000  349.000000  349.000000   \n",
       "mean     4.495702    3.212034    3.326648    2.888252    3.289398    3.529037   \n",
       "std      2.946478    3.159691    3.067611    2.887071    2.305522    3.651567   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      2.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "50%      4.000000    1.000000    2.000000    1.000000    2.000000    1.000000   \n",
       "75%      6.000000    5.000000    5.000000    4.000000    4.000000    7.000000   \n",
       "max     10.000000   10.000000   10.000000   10.000000   10.000000   10.000000   \n",
       "\n",
       "        chromatin    nucleoli     mitoses  \n",
       "count  349.000000  349.000000  349.000000  \n",
       "mean     3.469914    2.896848    1.621777  \n",
       "std      2.406250    3.075808    1.814750  \n",
       "min      1.000000    1.000000    1.000000  \n",
       "25%      2.000000    1.000000    1.000000  \n",
       "50%      3.000000    1.000000    1.000000  \n",
       "75%      5.000000    3.000000    1.000000  \n",
       "max     10.000000   10.000000   10.000000  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_Train_Trans = X_train\n",
    "StandardScaler_X_train = preprocessing.StandardScaler().fit_transform(X_train)\n",
    "StandardScaler_X_test = preprocessing.StandardScaler().fit_transform(X_test)\n",
    "\n",
    "MinMaxScaler_X_train = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
    "MinMaxScaler_X_test = preprocessing.MinMaxScaler().fit_transform(X_test)\n",
    "\n",
    "\n",
    "MaxAbsScaler_X_train = preprocessing.MaxAbsScaler().fit_transform(X_train)\n",
    "MaxAbsScaler_X_test = preprocessing.MaxAbsScaler().fit_transform(X_test)\n",
    "\n",
    "Normalizer_X_train = preprocessing.Normalizer().fit_transform(X_train)\n",
    "Normalizer_X_test = preprocessing.Normalizer().fit_transform(X_test)\n",
    "T = X_train # No Change\n",
    "T.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA and Isomap are your new best friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 2D Isomap Manifold\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "\n",
    "if Test_PCA:\n",
    "    print('Computing 2D Principle Components')\n",
    "    # TODO: Implement PCA here. Save your model into the variable 'model'.\n",
    "    # You should reduce down to two dimensions.\n",
    "    model = PCA(n_components = 2, svd_solver = \"randomized\")\n",
    "   \n",
    "else:\n",
    "    print('Computing 2D Isomap Manifold')\n",
    "    # TODO: Implement Isomap here. Save your model into the variable 'model'\n",
    "    # Experiment with K values from 5-10.\n",
    "    # You should reduce down to two dimensions.\n",
    "    model = Isomap(n_neighbors = 8 , n_components =2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model against data_train, then transform both `data_train` and `data_test` using your model. You can save the results right back into the variables themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = model.fit_transform(Normalizer_X_train)\n",
    "data_test = model.transform(Normalizer_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement and train `KNeighborsClassifier` on your projected 2D training data here. You can name your variable `knmodel`. You can use any `K` value from 1 - 15, so play around with it and see what results you can come up. Your goal is to find a good balance where you aren't too specific (low-K), nor are you too general (high-K). You should also experiment with how changing the weights parameter affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knmodel = KNeighborsClassifier(n_neighbors=10)\n",
    "knmodel.fit(data_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to always keep the domain of the problem in mind! It's WAY more important to errantly classify a benign tumor as malignant, and have it removed, than to incorrectly leave a malignant tumor, believing it to be benign, and then having the patient progress in cancer. Since the UDF weights don't give you any class information, the only way to introduce this data into SKLearn's KNN Classifier is by \"baking\" it into your data. For example, randomly reducing the ratio of benign samples compared to malignant samples from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Calculate and display the accuracy of the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822857142857\n"
     ]
    }
   ],
   "source": [
    "accuracy = knmodel.score(data_test,y_test)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-211fd751ce9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mknmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0marray1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "array1 = ()\n",
    "for i in range(5,10):\n",
    "    print (i)\n",
    "    model = Isomap(n_neighbors = i , n_components =2)\n",
    "    for n_neighbors_ in range(5,15):\n",
    "        for weights in ['uniform', 'distance']:\n",
    "            data_train = model.fit_transform(MinMaxScaler_X_train)\n",
    "            data_test = model.transform(MinMaxScaler_X_test)\n",
    "            knmodel = KNeighborsClassifier(n_neighbors=n_neighbors_, weights=weights)\n",
    "            knmodel.fit(data_train, y_train)\n",
    "            accuracy = knmodel.score(data_test,y_test)\n",
    "            array1.append(weights, n_neighbors_, accuracy)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Best parameters of knn: {'weights': 'uniform', 'n_neighbors': 8}\n",
      "Best scrore of knn: 0.9742120343839542\n",
      "6\n",
      "Best parameters of knn: {'weights': 'uniform', 'n_neighbors': 5}\n",
      "Best scrore of knn: 0.9742120343839542\n",
      "7\n",
      "Best parameters of knn: {'weights': 'uniform', 'n_neighbors': 8}\n",
      "Best scrore of knn: 0.9742120343839542\n",
      "8\n",
      "Best parameters of knn: {'weights': 'distance', 'n_neighbors': 13}\n",
      "Best scrore of knn: 0.9770773638968482\n",
      "9\n",
      "Best parameters of knn: {'weights': 'uniform', 'n_neighbors': 8}\n",
      "Best scrore of knn: 0.9742120343839542\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "for i in range(5,10):\n",
    "    model = Isomap(n_neighbors = i , n_components =2)\n",
    "    data_train = model.fit_transform(MinMaxScaler_X_train)\n",
    "    data_test = model.transform(MinMaxScaler_X_test)\n",
    "    knmodel = KNeighborsClassifier()\n",
    "    param_grid = {\"n_neighbors\" : [5,6,7,8,9,10,11,12,13,14,15], \"weights\" : [\"distance\",\"uniform\"]}\n",
    "    grid_search = GridSearchCV(knmodel, param_grid=param_grid, cv=10)\n",
    "    grid_search.fit(data_train, y_train)\n",
    "    print (i)\n",
    "    print ('Best parameters of knn:' , grid_search.best_params_)\n",
    "    print ('Best scrore of knn:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance, because each data point should contribute to the classification weighted by distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEJCAYAAACdePCvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni7mS2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dce0518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = model.fit_transform(MinMaxScaler_X_train)\n",
    "data_test = model.transform(MinMaxScaler_X_test)\n",
    "knmodel = KNeighborsClassifier(n_neighbors=13, weights=\"distance\")\n",
    "knmodel.fit(data_train, y_train)\n",
    "plotDecisionBoundary(knmodel, data_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
